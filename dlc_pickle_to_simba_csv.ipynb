{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoMzn/7iEONcx0vGeNri0u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vchiang001/sexual_diversity_dissertation/blob/main/dlc_pickle_to_simba_csv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaLkfGl-LlDv"
      },
      "outputs": [],
      "source": [
        "#This script is adapted from https://github.com/lapphe/AMBER-pipeline/blob/main/pheno_pickle_raw.py\n",
        "import pickle\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import ruamel.yaml"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#function to unpickle pickle file\n",
        "def unpickle_input(file_path, directory_path, max_tracks, empty_cell_val):\n",
        "    print('   Unpickling', file_path)\n",
        "    df = pd.read_pickle(file_path)\n",
        "    print('   Read pickle file with', len(df), 'frames containing detections')\n",
        "\n",
        "    body_parts = ['L_Eye', 'Btw_Eye', 'R_Eye', 'Nose', 'L_Ear', 'Btw_Ear', 'R_Ear', 'R_Paw', 'L_Paw', 'L_Foot', 'R_Foot', 'Tail_Base',\n",
        "                  'Tail_Mid_Base', 'Tail_Mid', 'Tail_Mid_End', 'Tail_End', 'Spine_1', 'Spine_2', 'Spine_3', 'Spine_4', 'Spine_5', 'Spine_3_L1',\n",
        "                  'Spine_3_L2', 'Spine_3_L3', 'Spine_3_L4', 'Spine_3_L5', 'Spine_3_R1', 'Spine_3_R2', 'Spine_3_R3', 'Spine_3_R4', 'Spine_3_R5']\n",
        "\n",
        "    columns = ['frame']\n",
        "    for pup in range(max_tracks):\n",
        "        for part in body_parts:\n",
        "            columns.append('pup' + str(pup+1) + '_' + part + '_x')\n",
        "            columns.append('pup' + str(pup+1) + '_' + part + '_y')\n",
        "            columns.append('pup' + str(pup+1) + '_' + part + '_likelihood')\n",
        "\n",
        "    output = []\n",
        "\n",
        "    counter = 0\n",
        "    for k, v in df.items():\n",
        "        counter += 1\n",
        "        if not k.startswith('frame'):\n",
        "            continue\n",
        "        row = k[5:]\n",
        "\n",
        "        data_row = dict.fromkeys(columns)\n",
        "        data_row['frame'] = row\n",
        "\n",
        "        # Read the coordinates and put them into data_row in the correct shape\n",
        "        for bp, arr in enumerate(v['coordinates'][0]):\n",
        "            for p, xy_coords in enumerate(arr):\n",
        "                if p < max_tracks:\n",
        "                    data_row['pup' + str(p+1) + '_' + body_parts[bp] + '_x'] = xy_coords[0]\n",
        "                    data_row['pup' + str(p+1) + '_' + body_parts[bp] + '_y'] = xy_coords[1]\n",
        "\n",
        "        # Read the confidences and put them into data_row\n",
        "        for bp, arr in enumerate(v['confidence']):\n",
        "            for p, pup_conf in enumerate(arr):\n",
        "                if p < max_tracks:\n",
        "                    data_row['pup' + str(p+1) + '_' + body_parts[bp] + '_likelihood'] = pup_conf[0]\n",
        "\n",
        "        # for i in range(len(confidence_row)):\n",
        "        output.append(data_row)\n",
        "\n",
        "        if counter > 10000000:\n",
        "            print('   Hit the maximum of 10 MILLION frames..')\n",
        "            break\n",
        "\n",
        "    output_file = pd.DataFrame.from_dict(output)\n",
        "    output_file = output_file.set_index('frame')\n",
        "    output_file.fillna(empty_cell_val, inplace=True)\n",
        "    output_file = output_file.sort_values(by='frame')\n",
        "\n",
        "    output_file_name = file_path.split('.')[-2].split(os.sep)[-1] + '_UNPICKLED.csv'\n",
        "\n",
        "    output_path = directory_path + os.sep + output_file_name\n",
        "    print('   Writing output to:', output_path)\n",
        "\n",
        "    output_file.to_csv(output_path)\n",
        "    print('   Done unpickling file!')"
      ],
      "metadata": {
        "id": "iZcQXMi0MCmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to apply to all pickle files in the directory\n",
        "def main(args, max_tracks=2, empty_cell_val='NA', file_path=None, directory_path=None):\n",
        "    input_files = []\n",
        "    file_name = None\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    print('--- PhenoPickleRaw ---')\n",
        "\n",
        "    if len(args) == 1:\n",
        "        show_help()\n",
        "        return\n",
        "\n",
        "    if args[1] == '-h':\n",
        "        show_help()\n",
        "        return\n",
        "\n",
        "    for arg in args:\n",
        "        if arg.startswith('-input_directory:'):\n",
        "            directory_path = arg[len('-input_directory:'):]\n",
        "            directory_path = directory_path.replace(\"'\", '')\n",
        "            directory_path = directory_path.replace('\"', '')\n",
        "    if directory_path is None:\n",
        "        print('Error! No input folder specified.')\n",
        "        return\n",
        "\n",
        "    for arg in args:\n",
        "        if arg.startswith('-input_file:'):\n",
        "            file_name = arg[len('-input_file:'):]\n",
        "            input_files = directory_path + os.sep + file_name\n",
        "    if file_name is None:\n",
        "        print('Input file not specified, search directory.')\n",
        "        files = os.listdir(directory_path)\n",
        "        for file in files:\n",
        "            if file.endswith('full.pickle'):\n",
        "                input_files.append(directory_path + os.sep + file)\n",
        "    print(len(input_files), 'full pickle files found.')\n",
        "\n",
        "    for arg in args:\n",
        "        if arg[0:7] == '-output':\n",
        "            output_path = arg[8:]\n",
        "            if output_path[-4:] != '.csv':\n",
        "                print(output_path)\n",
        "                print('Output does not end with .csv!', output_path[-4:])\n",
        "                return\n",
        "\n",
        "    for arg in args:\n",
        "        if arg[0:12] == '-max_tracks':\n",
        "            max_tracks = arg[13:]\n",
        "            print('Max tracks:', max_tracks)\n",
        "\n",
        "    for arg in args:\n",
        "        if arg[0:17] == '-empty_cell_val':\n",
        "            empty_cell_val = arg[18:]\n",
        "            print('Empty cell val:', empty_cell_val)\n",
        "\n",
        "    for file in input_files:\n",
        "        if file.endswith('meta.pickle'):\n",
        "            continue\n",
        "        unpickle_input(file, directory_path, max_tracks=max_tracks, empty_cell_val=empty_cell_val)\n",
        "\n",
        "    print('Done unpickling all files.')\n",
        "    return\n"
      ],
      "metadata": {
        "id": "p2CuEA9BMVsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main(['-input_directory:C:\\\\Users\\\\vscch_\\\\OneDrive\\Desktop\\\\behaviomics\\\\combined_lowres_dataset',\n",
        "      '-output:output.csv',\n",
        "      '-max_tracks:2',\n",
        "      '-empty_cell_val:NA'])"
      ],
      "metadata": {
        "id": "RkJ6rM-fMo_Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}